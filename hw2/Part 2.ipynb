{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "gFe273vKFgF-"
   },
   "source": [
    "# Homework 2\n",
    "## Part 2 (60 points total)\n",
    "\n",
    "In this part, you will build a convolutional neural network (aka ConvNet or CNN) to solve yet another image classification problem: the Tiny ImageNet dataset (200 classes, 100K training images, 10K validation images). Try to achieve as high accuracy as possible.\n",
    "\n",
    "This exercise is close to what people do in real life. No toy architectures this time. **Unlike in part 1**, you are now free to use the full power of PyTorch and its submodules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from timeit import default_timer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "def get_dataloader(path, kind):\n",
    "    \"\"\"\n",
    "    Return dataloader for a `kind` split of Tiny ImageNet.\n",
    "    If `kind` is 'val', the dataloader should be deterministic.\n",
    "\n",
    "    path:\n",
    "        `str`\n",
    "        Path to the dataset root - a directory which contains 'train' and 'val' folders.\n",
    "    kind:\n",
    "        `str`\n",
    "        'train' or 'val'\n",
    "\n",
    "    return:\n",
    "    dataloader:\n",
    "        `torch.utils.data.DataLoader` or an object with equivalent interface\n",
    "        For each batch, should yield a tuple `(preprocessed_images, labels)` where\n",
    "        `preprocessed_images` is a proper input for `predict()` and `labels` is a\n",
    "        `torch.int64` tensor of shape `(batch_size,)` with ground truth class labels.\n",
    "    \"\"\"\n",
    "\n",
    "    class RandomNoise:\n",
    "        def __init__(self, sigma=0.025):\n",
    "            self.sigma = sigma\n",
    "\n",
    "        def __call__(self, x):\n",
    "            noise = torch.normal(0, self.sigma, size=x.shape)\n",
    "            return x + noise\n",
    "\n",
    "    preprocessing_train = transforms.Compose([\n",
    "        transforms.RandomApply([\n",
    "            # transforms.GaussianBlur(4),\n",
    "            transforms.RandomResizedCrop(64, scale=(0.66, 1.0), ratio=(0.8, 1.2)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "            transforms.RandomAffine(20, (0.2, 0.2)),\n",
    "        ], p=0.7),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([RandomNoise(),], p=0.5),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    preprocessing_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    if kind == 'val':\n",
    "        dataset = torchvision.datasets.ImageFolder(os.path.join(path, kind), transform=preprocessing_val)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    elif kind == 'train':\n",
    "        dataset = torchvision.datasets.ImageFolder(os.path.join(path, kind), transform=preprocessing_train)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown kind: {kind}')\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Create neural net object, initialize it with raw weights, upload it to GPU.\n",
    "\n",
    "    return:\n",
    "    model:\n",
    "        `torch.nn.Module`\n",
    "    \"\"\"\n",
    "    class BasicBlock_(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, downsample=True, relu=True):\n",
    "            super().__init__()\n",
    "            s = 2 if downsample else 1    \n",
    "            self.backbone = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, s, 1, groups=in_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1, groups=out_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "            self.downsample = downsample\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, 1)\n",
    "            self.relu = relu\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.backbone(x)\n",
    "            identity = F.avg_pool2d(x, 2) if self.downsample else x\n",
    "            out += self.shortcut(identity)\n",
    "            if self.relu:\n",
    "                out = F.leaky_relu(out)\n",
    "            return out\n",
    "\n",
    "    class BasicBlock(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, downsample=True, relu=True, r=2):\n",
    "            super().__init__()\n",
    "            self.basic_block = BasicBlock_(in_channels, out_channels, downsample, relu)\n",
    "            self.squeeze_and_excitation_block = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(out_channels, out_channels // r),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Linear(out_channels // r, out_channels),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.basic_block(x)\n",
    "            out *= self.squeeze_and_excitation_block(out)[..., None, None]\n",
    "\n",
    "            return out\n",
    "\n",
    "    class MobileResnetV2(nn.Module):\n",
    "        def __init__(self, num_classes=200):\n",
    "            super(MobileResnetV2, self).__init__()\n",
    "            self.conv = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "            self.bn = nn.BatchNorm2d(64)\n",
    "            self.backbone = nn.Sequential(\n",
    "                BasicBlock(64,  64,  True, r=4),\n",
    "                BasicBlock(64,  128, True, r=4),\n",
    "                BasicBlock(128, 128, False, r=4),\n",
    "                BasicBlock(128, 256, True, r=8),\n",
    "                BasicBlock(256, 256, False, r=8),\n",
    "                BasicBlock(256, 512, True, r=8),\n",
    "                BasicBlock(512, 512, False, r=8),\n",
    "            )\n",
    "            self.dropout = nn.Dropout(p=0.25, inplace=True)\n",
    "            self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.conv(x)\n",
    "            out = F.leaky_relu(self.bn(out))\n",
    "            out = self.backbone(out)\n",
    "            out = F.avg_pool2d(out, (4, 4))\n",
    "            out = out.view(out.shape[0], -1)\n",
    "            out = self.dropout(out)\n",
    "            out = self.linear(out)\n",
    "\n",
    "            return out\n",
    "\n",
    "\n",
    "    model = MobileResnetV2()\n",
    "\n",
    "    return model.to('cuda')\n",
    "\n",
    "def get_optimizer(model):\n",
    "    \"\"\"\n",
    "    Create an optimizer object for `model`, tuned for `train_on_tinyimagenet()`.\n",
    "\n",
    "    return:\n",
    "    optimizer:\n",
    "        `torch.optim.Optimizer`\n",
    "    \"\"\"\n",
    "    return torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=6e-4)\n",
    "\n",
    "def predict(model, batch):\n",
    "    \"\"\"\n",
    "    model:\n",
    "        `torch.nn.Module`\n",
    "        The neural net, as defined by `get_model()`.\n",
    "    batch:\n",
    "        unspecified\n",
    "        A batch of Tiny ImageNet images, as yielded by `get_dataloader(..., 'val')`\n",
    "        (with same preprocessing and device).\n",
    "\n",
    "    return:\n",
    "    prediction:\n",
    "        `torch.tensor`, shape == (N, 200), dtype == `torch.float32`\n",
    "        The scores of each input image to belong to each of the dataset classes.\n",
    "        Namely, `prediction[i, j]` is the score of `i`-th minibatch sample to\n",
    "        belong to `j`-th class.\n",
    "        These scores can be 0..1 probabilities, but for better numerical stability\n",
    "        they can also be raw class scores after the last (usually linear) layer,\n",
    "        i.e. BEFORE softmax.\n",
    "    \"\"\"\n",
    "    return model.forward(batch.to('cuda'))\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(dataloader, model):\n",
    "    \"\"\"\n",
    "    Run `model` through all samples in `dataloader`, compute accuracy and loss.\n",
    "\n",
    "    dataloader:\n",
    "        `torch.utils.data.DataLoader` or an object with equivalent interface\n",
    "        See `get_dataloader()`.\n",
    "    model:\n",
    "        `torch.nn.Module`\n",
    "        See `get_model()`.\n",
    "\n",
    "    return:\n",
    "    accuracy:\n",
    "        `float`\n",
    "        The fraction of samples from `dataloader` correctly classified by `model`\n",
    "        (top-1 accuracy). `0.0 <= accuracy <= 1.0`\n",
    "    loss:\n",
    "        `float`\n",
    "        Average loss over all `dataloader` samples.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    loss = accuracy = 0\n",
    "    bs = dataloader.batch_size\n",
    "    n = len(dataloader)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        predictions = predict(model, inputs)\n",
    "        loss += criterion(predictions, labels)\n",
    "        accuracy += (labels == torch.argmax(predictions, dim=1)).sum() / bs\n",
    "\n",
    "    return accuracy / n, loss / n\n",
    "\n",
    "def train_on_tinyimagenet(train_dataloader, val_dataloader, model, optimizer, exp_name):\n",
    "    \"\"\"\n",
    "    Train `model` on `train_dataloader` using `optimizer`. Use best-accuracy settings.\n",
    "\n",
    "    train_dataloader:\n",
    "    val_dataloader:\n",
    "        See `get_dataloader()`.\n",
    "    model:\n",
    "        See `get_model()`.\n",
    "    optimizer:\n",
    "        See `get_optimizer()`.\n",
    "    \"\"\"\n",
    "    n_epochs = 80\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 5e-4, eta_min=5e-6, last_epoch=-1)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, gamma=0.3)\n",
    "\n",
    "    os.mkdir(exp_name)\n",
    "    os.mkdir(exp_name + '/tensorboard')\n",
    "    writer = SummaryWriter(exp_name + '/tensorboard')\n",
    "\n",
    "    best_loss = 1e5\n",
    "    n_train = len(train_dataloader)\n",
    "    for epoch in range(n_epochs):\n",
    "        t1 = default_timer()\n",
    "        loss_train = 0\n",
    "        model.train()\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss_train += loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        acc_val, loss_val = validate(val_dataloader, model)\n",
    "        scheduler.step()\n",
    "\n",
    "        t2 = default_timer()\n",
    "        epoch_time = t2 - t1\n",
    "        writer.add_scalar('time', epoch_time, epoch)\n",
    "        writer.add_scalar('train_loss', loss_train.item() / n_train, epoch)\n",
    "        writer.add_scalar('val_acc', acc_val.item(), epoch)\n",
    "        writer.add_scalar('val_loss', loss_val.item(), epoch)\n",
    "        # writer.add_scalar('l2_norm_linear1', model.linear1.weight.norm().item(), epoch)\n",
    "        # writer.add_scalar('l2_norm_linear2', model.linear2.weight.norm().item(), epoch)\n",
    "        writer.add_scalar('l2_norm_linear', model.linear.weight.norm().item(), epoch)\n",
    "\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, exp_name + '/checkpoint.pth')\n",
    "\n",
    "\n",
    "def load_weights(model, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Initialize `model`'s weights from `checkpoint_path` file.\n",
    "\n",
    "    model:\n",
    "        `torch.nn.Module`\n",
    "        See `get_model()`.\n",
    "    checkpoint_path:\n",
    "        `str`\n",
    "        Path to the checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "def get_checkpoint_metadata():\n",
    "    \"\"\"\n",
    "    Return hard-coded metadata for 'checkpoint.pth'.\n",
    "    Very important for grading.\n",
    "\n",
    "    return:\n",
    "    md5_checksum:\n",
    "        `str`\n",
    "        MD5 checksum for the submitted 'checkpoint.pth'.\n",
    "        On Linux (in Colab too), use `$ md5sum checkpoint.pth`.\n",
    "        On Windows, use `> CertUtil -hashfile checkpoint.pth MD5`.\n",
    "        On Mac, use `$ brew install md5sha1sum`.\n",
    "    google_drive_link:\n",
    "        `str`\n",
    "        View-only Google Drive link to the submitted 'checkpoint.pth'.\n",
    "        The file must have the same checksum as in `md5_checksum`.\n",
    "    \"\"\"\n",
    "    # Your code here; md5_checksum = \"747822ca4436819145de8f9e410ca9ca\"\n",
    "    # Your code here; google_drive_link = \"https://drive.google.com/file/d/1uEwFPS6Gb-BBKbJIfv3hvdaXZ0sdXtOo/view?usp=sharing\"\n",
    "\n",
    "    return None, None #md5_checksum, google_drive_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S-WyYK8FgGF"
   },
   "source": [
    "## Grading\n",
    "\n",
    "* 11 points for the report.\n",
    "* 5 points for using an **interactive** (please don't reinvent the wheel with `plt.plot`) tool for viewing progress, for example TensorBoard.\n",
    "* 9 points for a network that gets above 25% accuracy on the private **test** set.\n",
    "* Up to 35 points for accuracy up to 50%, issued linearly (i.e. 0 points for 25%, 7 points for 30%, 21 points for 40%, 35 points for $\\geq$50%.\n",
    "\n",
    "## Grading Explained\n",
    "\n",
    "* *Private test set*: it's a part of the dataset like the validation set, but for which the ground truth labels are known only to us (you won't be able to evaluate your model on it). When grading, we will compute test accuracy by running your code that computes val accuracy, but having replaced the images in `'val/'` with the test set.\n",
    "* *Submitting a neural net*:\n",
    "  * **<font color=\"red\">Wrong checkpoint submission = zero points for accuracy. Be careful!</font>**\n",
    "  * After you've trained your network, [save weights](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) to \"*checkpoint.pth*\" with `model.state_dict()` and `torch.save()`.\n",
    "  * Set `DO_TRAIN = False`, click \"Restart and Run All\" and make sure that your validation accuracy is computed correctly.\n",
    "  * Compute the MD5 checksum for \"*checkpoint.pth*\" (e.g. run `!md5sum checkpoint.pth`) and paste it into \"*part2_solution.py*\" (`get_checkpoint_metadata()`). You'll be penalized if this checksum doesn't match your submitted file.\n",
    "  * Upload \"*checkpoint.pth*\" to Google Drive, copy the view-only link to it and paste it into \"*part2_solution.py*\" as well.\n",
    "* *Report*: PDF, free form; rough list of points to touch upon:\n",
    "  * Your history of tweaks and improvements. How you started, what you searched. (*I have analyzed these and those conference papers/sources/blog posts. I tried this and that to adapt them to my problem. ...*)\n",
    "  * Which network architectures have you tried? Which of them didn't work, and can you guess why? What is the final one and why?\n",
    "  * Same for the training method (batch size, optimization algorithm, number of iterations, ...): which and why?\n",
    "  * Same for anti-overfitting (regularization) techniques. Which ones have you tried? What were their effects, and can you guess why?\n",
    "  * **Most importantly**: deep learning insights you gained. Can you give several examples of how *exactly* experience from this exercise will affect you training your future neural nets? (tricks, heuristics, conclusions, observations)\n",
    "  * **List all sources of code**.\n",
    "* *Progress viewing tool*: support the report with screenshots of accuracy and loss plots (training and validation) over time.\n",
    "\n",
    "## Restrictions\n",
    "\n",
    "* No pretrained networks.\n",
    "* Don't enlarge images (e.g. don't resize them to $224 \\times 224$ or $256 \\times 256$).\n",
    "\n",
    "## Tips\n",
    "\n",
    "* **One change at a time**: don't test several new things at once (unless you are super confident that they will work). Train a model, introduce one change, train again.\n",
    "* Google a lot: try to reinvent as few wheels as possible (unlike in part 1 of this assignment). Harvest inspiration from PyTorch recipes, from GitHub, from blogs...\n",
    "* Use GPU.\n",
    "* Regularization is very important: L2, batch normalization, dropout, data augmentation...\n",
    "* Pay much attention to accuracy and loss graphs (e.g. in TensorBoard). Track failures early, stop bad experiments early.\n",
    "* 2-3 hours of training (in Colab) should be enough for most models, maybe 4-6 hours if you're experimenting.\n",
    "* Save checkpoints every so often in case things go wrong (optimization diverges, Colab disconnects...).\n",
    "* Don't use too large batches, they can be slow and memory-hungry. This is true for inference too (also don't forget `torch.no_grad()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X5eKWQv9wi3P"
   },
   "outputs": [],
   "source": [
    "DO_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AFqnb1-EFgGj"
   },
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(\"./tiny-imagenet-200/\", 'train')\n",
    "val_dataloader   = get_dataloader(\"./tiny-imagenet-200/\", 'val')\n",
    "\n",
    "# train_dataloader = get_dataloader(\"./tiny-imagenet-200/\", 'train')\n",
    "# val_dataloader   = get_dataloader(\"./small_dataset/\", 'val')\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J9n7DyGcFgGq"
   },
   "outputs": [],
   "source": [
    "# ExiBlock was mobile v1 with less deca, 2 linear, bigger squeze linears\n",
    "# if DO_TRAIN:\n",
    "#     # load_weights(model, 'small_dataset_exp/checkpoint.pth')\n",
    "#     optimizer = get_optimizer(model)\n",
    "#     train_on_tinyimagenet(train_dataloader, val_dataloader, model, optimizer, 'LastLast')\n",
    "# else:\n",
    "#     # Load from disk\n",
    "#     load_weights(model, './RandomTransfGauss/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-024bda0aac88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load_weights(model, 'RandomTransfGauss/checkpoint.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_on_tinyimagenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FineTuneFineTune'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-bdfcc14089a4>\u001b[0m in \u001b[0;36mtrain_on_tinyimagenet\u001b[0;34m(train_dataloader, val_dataloader, model, optimizer, exp_name)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alexander/8727f95c-3d52-46d0-bea9-a4f7278a6d7a/ProgramSetups/miniconda3/envs/cv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alexander/8727f95c-3d52-46d0-bea9-a4f7278a6d7a/ProgramSetups/miniconda3/envs/cv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alexander/8727f95c-3d52-46d0-bea9-a4f7278a6d7a/ProgramSetups/miniconda3/envs/cv/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/alexander/8727f95c-3d52-46d0-bea9-a4f7278a6d7a/ProgramSetups/miniconda3/envs/cv/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load_weights(model, 'RandomTransfGauss/checkpoint.pth')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=6e-4)\n",
    "train_on_tinyimagenet(train_dataloader, val_dataloader, model, optimizer, 'FineTuneFineTune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_on_tinyimagenet(train_dataloader, val_dataloader, model, optimizer, 'ExitBlocksCuttedContinue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CDJw8MokFxP9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class / Ground truth class\n",
      "000 / 000\n",
      "189 / 000\n",
      "189 / 000\n",
      "181 / 000\n",
      "049 / 000\n",
      "009 / 000\n",
      "194 / 000\n",
      "139 / 000\n",
      "152 / 000\n",
      "154 / 000\n",
      "000 / 000\n",
      "095 / 000\n",
      "061 / 000\n",
      "040 / 000\n",
      "161 / 000\n"
     ]
    }
   ],
   "source": [
    "example_batch, example_batch_labels = next(iter(val_dataloader))\n",
    "_, example_predicted_labels = predict(model, example_batch).max(1)\n",
    "\n",
    "print(\"Predicted class / Ground truth class\")\n",
    "for predicted, gt in list(zip(example_predicted_labels, example_batch_labels))[:15]:\n",
    "    print(\"{:03d} / {:03d}\".format(predicted, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U_Qddecy7-uS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 47.65%\n"
     ]
    }
   ],
   "source": [
    "val_accuracy, _ = validate(val_dataloader, model)\n",
    "print(\"Validation accuracy: %.2f%%\" % (100 * val_accuracy))\n",
    "assert 1.5 <= 100 * val_accuracy <= 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy accuracy: 76.87%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, _ = validate(train_dataloader, model)\n",
    "print(\"train_accuracy accuracy: %.2f%%\" % (100 * train_accuracy))\n",
    "assert 1.5 <= 100 * train_accuracy <= 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URNOeZ0MSZuq"
   },
   "outputs": [],
   "source": [
    "md5_checksum, google_drive_link = part2_solution.get_checkpoint_metadata()\n",
    "print(f\"Claimed MD5 checksum: {md5_checksum}\")\n",
    "print(\"Real MD5 checksum:\")\n",
    "!md5sum checkpoint.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2eed83fb22602b9dfe5316d6ea2c085b  RandomTransfGauss/checkpoint.pth\r\n"
     ]
    }
   ],
   "source": [
    "!md5sum RandomTransfGauss/checkpoint.pth"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
